---
tags:
  - Class
---

## 线性规划
### 基本概念
$$
\begin{array}{ll}
 \min z:= \sum_{i=1}^{n} \sum_{j=1}^n c_{ij}x_{ij}\\
 s.t. \sum_{i=1}^n x_{ij} \le d_j^+ ,j = 1,...,n\\
 \quad \sum_{j=1}^n x_{ij} \le d_i^-,i = 1,...,n\\
 \quad x_{ij} \le 0, i,j \in \{1,2,...,n\}
 \end{array}
$$
#### 线性规划的转换方法
**标准形式**：
- 目标：$\min$ 极小
- 约束1: 等式约束
- 约束2: 对于决策变量有非负要求
#### 线性规划的几何意义

![[Pasted image 20250423154355.png]]
### 线性规划的基本定理

#### 凸集
![[Pasted image 20250423154454.png]]
#### 超平面与闭半空间
- 称形如$\{x\in R^n:a^Tx = \beta\}$ 的集合为**超平面**
- $\{x\in R^n:a^Tx \le \beta\}$ 与 $\{x\in R^n:a^Tx \ge \beta\}$ 称为超平面 $\{x\in R^n:a^Tx = \beta\}$分成的两个**闭半空间**
#### 多面凸集与凸多面体


## 无约束优化

### 单目标优化
### 多目标优化

#### 共轭梯度法

##### 共轭定义

设 A 是 n 阶对称矩阵，p和q是n元列向量，如果 $p^T A q = 0$ ,那么称向量 $p$ 和 $q$  关于A矩阵共轭

 如果 $A=E_n$ ,则$p$ 和 $q$ 正交，共轭可以看作正交的推广若有$m$ 个 $n$ 元向量，$p_1,p_2,... , p_m$ 有 $$
 p_i^TAp_j = 0(i\neq j,i,j = 1,2,...,m)
 $$则称这个向量组为$A$的共轭方向组
 
 **定理**
1. 设$A$为$n$阶正定矩阵，一组$n$ 元非零向量 $p_1,p_2,...,p_m$ 是矩阵$A$ 的共轭方向组，那么此向量组线性无关
2. 设$A$ 为$n$ 阶正定矩阵，一组$n$元非零向量$p_1,p_2,...,p_n$ 是矩阵$A$的共轭方向组，若向量$q$与$p_1,p_2,...,p_n$关于$A$共轭，那么$q=0$
3. 设$A$ 为$n$ 阶正定矩阵，一组$n$元非零向量$p_1,p_2,...,p_n$ 是矩阵$A$的共轭方向组,对于二次函数$f(x) = a+b^Tx+\frac{1}{2}x^TA x$,由任意初始点$x_0$出发，进行精确一维搜索，得到$x^{i+1} = x^i+\alpha_id^i，i=0,1,2,...,k$,那么$$(\nabla f(x^{k+1}))^Td^i = 0,i=0,1,2,...,k$$
4. 设$A$ 为$n$ 阶正定矩阵, $d^0,d^1,...,d^{n-1} \in R^n$ 是矩阵 $A$ 的共轭方向组，对于问题 $\min f(x) = a+b^Tx+\frac{1}{2}x^TAx$,如果从初始点$x^0$出发，依次沿方向$d_0,d_1,...,d_{n-1}$ 进行精确一维搜索，那么最多经过$n$次迭代，即可得到$f(x)$的极小值点

##### Fletcher-Reeves 公式
在共轭方向法的基础上，新的一步利用好前一步的数据，确定一个步长，更新下降方向，使得**非二次函数也能进行共轭方向法**


#### 直接搜索法

多变量函数极值，不计算导数的优化算法
- 方法简单，适用范围广
- 收敛速度比较慢
##### 坐标轮换法
沿着 $n$ 个坐标轴的方向轮流搜索，在每一次的搜索中，只对 $n$ 元函数的一个变量沿着其坐标轴的方向进行以为搜索，另外 $n-1$ 个变量保持不变，将 $n$ 维优化问题转为单变量问题。
##### Powell 方向加速法
没有共轭梯度向量时数值模拟出一个
- 基本搜索
- 加速搜索
- 调整搜索方向
##### 定理
- 对于正定二次函数 $f(x) = a+b^Tx+\frac{1}{2}x^TAx,d^0,d^1,...,d^{k-1} \in R^n(k \textless n)$ 是矩阵$A$ 的共轭方向组，如果分别从初始点 $x^0$ 和 $x^1$ 出发，依次沿方向 $d^0,d^1,...,d^{k-1}$ 进行一维搜索，并设最后得到的点是 $x^a$ 和 $x^b$ ，如果 $x^a \neq x^b$ 那么 $x^a-x^b$ 与 $d_0,d_1,...,d_{k-1}$ 关于 $A$ 是共轭的，即 $$(x^a-x^b)^T Ad^j=0,j=0,1,2,...,k-1$$
##### Hooke-Jeeves 方法
两类移动
- **探测搜索**：在初始点周围探测，寻找有利的下降方向
- **模式搜索**：沿着有利的方向加速，获得新的初始点

## 约束最优化
基本形式$$ 
\begin{array}{ll}
\min_{x\in R^n} f(x) \\ \\
s.t. h_i(x) = 0 (i=1,2,...,l) \\
h_i(x\leq 0) (i=l+1,l+2,...,m) 
\end{array}$$
其中 $f,h_i,i=1,2,...,m$ 均为 $R^n$ 或其子集上的连续可微实值函数

- 满足所有约束条件构成的点叫做**可行域**，记为 $\Omega$
- 可行域中的点，即 $x \in \Omega$ 为**可行点**
- **可行方向**: 非零向量 $d$ 称为点 $x^* \in \Omega$ 处的一个可行方向，如果存在一个数 $t^* \gt 0$ ，使得对于任意的 $t \in (0,t^*),都有x^* + td \in \Omega$，非零向量 $d$ 称为点 $x^* \in \Omega$ 的一个可行下降方向，如果存在一个数 $t^* \gt 0$,使得对任意的 $t \in (0,t^*)$ 都有 $f(x^*+td) \lt f(x^*)$ 且 $x^*+td \in \Omega$

### 非线性规划的一阶最优性条件
$$
\begin{array}{ll}
\min f(x) \\

	s.t.h_i(x)= 0 (i=1,2,...,l)
	\end{array}
	$$
#### 必要条件：
存在 $\mu^* = (\mu_1^*,...,\mu_l^*)^T \in R^l$ 使得$$\nabla_xL(x^*,\mu^*)=\nabla f(x^*)+\sum_{i=1}^l\mu_i^*\nabla h_i(x^*) = 0$$
其中 $L(x,\mu) := f(x)+\sum_{i=1}^l\mu_ih_i(x)$ 

#### Karush-Kuhn-Tucker 条件
存在 $\lambda^* \in R^m$ 使得$$\nabla_xL(x^*,\lambda^*)=\nabla f(x^*)+\sum_{i=1}^l\lambda_i^*\nabla h_i(x^*) = 0$$
$$\begin{array}{ll}
h_i(x^*) = 0,i = 1,2,...,l\\
h_i(x^*) \le = 0,i= l+1,l+2,...,m\\
\lambda_i^*h_i(x^*)= 0,i = l+1,l+2,...,m\\
\lambda_i^* \ge 0,i=l+1,l+2,...,m
\end{array}$$
其中 $L(x,\mu) := f(x)+\sum_{i=1}^l\lambda_ih_i(x)$ 

### 凸规划问题
目标函数是凸函数，约束集合是凸集合
$$
\begin{array}{ll}
\min f(x) \\

	s.t.h_i(x)= 0 (i=1,2,...,l)
	\end{array}
	$$
**凸函数的充要条件**
对于凸集$\Omega$ 上的可微函数，对于所有的$x,y \in \Omega$都有$$ f(u) \ge f(x) + (\nabla f(x))^T(y-x) $$
**定理：凸规划问题的 KKT 点必为该问题的最优解**

**定理：设 $x^*$ 为最优解，且满足 Slater 条件： 
	$\exists \hat{x} \in R^n$ 满足$h_i(\hat{x}) = 0(i=1,...,l)$;$h_i(\hat{x}) < 0(i=l+1,l+2,...,m)$
$\hat{x} \in \Omega$ 称为绝对可行点，$x^*$为 KKT 点

### 二次规划
一般形式$$ \begin{array}{ll}
\min q(x) = \frac{1}{2} x^TGx + c^Tx\\
s.t. \begin{array}{ll}
a_i^T x = b_i(i=1,2,...,l)\\
a_i^T x \le b_i(i=l+1,l+2,...,p)
\end{array}
\end{array}$$
- $G$ 半正定，则问题是一个凸二次规划，任何局部最优解也一定是全局最优解
- $G$ 不定，则问题是一个非凸二次规划，可能存在多个 KKT 点或多个极小值点

#### 等式约束二次规划
 $$ \begin{array}{ll}\min q(x) = \frac{1}{2} x^T Gx + c^T x\\
 s.t. a_i^T x = b_i(i=1,2,...,l)\end{array}$$
令 $A = (a_1,a_2,...,a_l)^T$ ，$b = (b_1,b_2,...,b_l)^T$ 则有：
**定理**：设 $a_1,a_2,...,a_l$ 线性无关，$x^*$ 为问题的局部最优解，$x^*$也为问题的 KKT 点，即存在拉格朗日子 $\mu^*$,满足$$ \begin{pmatrix} G & A^T \\ A & 0 \end{pmatrix}\begin{pmatrix} x^* \\ \mu^* \end{pmatrix} = \begin{pmatrix} -c \\ b \end{pmatrix} $$
**定理**：设 $G$ 为半正定矩阵，$a_1,a_2,...,a_l$ 线性无关，$x^*$为问题的可行点，则$x^*$ 是该图规划问题的全局最优解的充分必要条件是 $x^*$ 为问题的 KKT 点

#### 起作用指标集方法
设 $x^*$ 是凸二次规划问题的最优解，$\mathcal{A}_* = \mathcal{A}(x^*)$为$x^*$处的起作用指标集，则 $x^*$ 也为下述问题的最优解 $$ \begin{array}{ll}\min q(x) = \frac{1}{2} x^T Gx + c^T x\\
 s.t. a_i^T x = b_i(i \in \mathcal{A}_*)\end{array}$$![[Pasted image 20250422130750.png]]

#### 序列二次规划方法 （SQP)

##### 求解非线性方程组的牛顿法
对于非线性方程组 $$r(x) = 0$$
其中$r:R^n \rightarrow R^n$ 为光滑映射，其分量形式为 $r(x) = (r_1(x),r_2(x),...,r_n(x))^T$,$r$ 在 $x$ 处的雅可比矩阵定义为$$ J(x) = (\nabla r_1(x),...,\nabla r_n(x))$$
上述非线性方程组可以使用牛顿法求解
![[Pasted image 20250422144950.png]]
##### SQP 算法
一般形式的非线性规划问题$$ \begin{array}{ll} \min \quad f(x)\\
s.t. \quad h_i(x) = 0 (i=1,2,...,l) \\
\quad \quad \quad h_i(x) \le 0 (i=l+1,l+2,...,m) \end{array}$$
每一步迭代，可以构建二次规划子问题$$\begin{array}{ll} \min \frac{1}{2} d^TB_kd+ \nabla f(x^k)^Td\\
s.t. \quad h_i(x^k)+ \nabla h_i(x^k)^Td = 0 (i=1,2,...,l)\\
\quad \quad \quad h_i(x^k) + \nabla h_i(x^k)^Td \le 0 (i=l+1,l+2,...,m)
\end{array}$$
其中，$B_k$ 为问题的拉格朗日函数关于 $x$ 的海森阵 $\nabla_{xx}^2L(x^k,\lambda^k)$

![[Pasted image 20250422151003.png]]

### 惩罚函数法与障碍函数法
对于约束优化问题而言，可以转换成无约束优化问题求解
#### 惩罚函数
针对带约束的
$$ \begin{array}{ll} \min \quad f(x)\\
s.t. \quad h_i(x) = 0 (i=1,2,...,l) \\
\quad \quad \quad h_i(x) \le 0 (i=l+1,l+2,...,m) \end{array}$$
优化问题，定义惩罚函数$$P(x,\rho) = f(x) + \rho p(x)$$
其中 $\rho > 0$ 为常数，称为惩罚因子，$\rho p(x)$为惩罚项，$p(x)$具备以下性质:
![[Pasted image 20250422153226.png]]
**常用的惩罚函数**
1. 等式约束
$$ \begin{array}{ll} \min \quad f(x)\\
s.t. \quad h_i(x) = 0 (i=1,2,...,l) \end{array}$$
则 $p(x)$ 可以构造成：$$ p(x) = \sum_{i=1}^l h^2_i(x) $$
2. 不等式约束$$ \begin{array}{ll} \min \quad f(x)\\
s.t.  \quad h_i(x) \le 0 (i=l+1,l+2,...,m) \end{array}$$
则$p(x)$ 可以构造成：$$ p(x) = \sum_{i = l+1} ^ m (\max\{0,h_i(x)\}^2)$$
综上：$$P(x,\rho) = f(x) + \rho [\sum_{i=0}^lh_i^2(x) + \sum_{i=l+1}^m(\max \{0,h_i(x)\})^2 ]$$
![[Pasted image 20250422154915.png]]
#### 障碍函数法
在约束边界上设置强制约束，使得无约束优化只能在可行域内部优化，**仅适合解决仅含不等式约束**的优化问题

考虑优化问题：$$ \begin{array}{ll} \quad \min f(x) \\ s.t. \quad h_i(x) \le 0(i = 1,2,...,m) \end{array}$$
其可行域 $\Omega$:$$ int \Omega := \{ x \in R^n : h_i(x) \le 0 (i = 1,2,...,m) \}$$
若 $int \Omega \neq \varnothing$，则可以定义障碍函数：$$ B(x,r) = f(x) + rb(x)$$
其中,$r > 0$为常数，也成为惩罚因子或障碍音系，$rb(x)$ 仍称为惩罚项
![[Pasted image 20250423114102.png]]

**障碍函数的两种形式**
- 倒数形式 $$ b(x) = \sum_{i=1}^m -\frac{1}{h_i(x)}$$
- 对数形式$$b(x) = \sum_{i=1}^m - \ln [\min(1,-h_i(x))]$$
由此问题可以转换成求解$$ \min_{x \in int \Omega} B{x,r}$$
![[Pasted image 20250423114643.png]]
#### 混合罚函数法
- 障碍函数法：仅限于求解不等式约束的优化问题
- 惩罚函数法：得到的近似最优解往往是不可行的

对于问题取混合惩罚函数为 $$ F(x,r_k) = f(x) +r_kb(x) + \frac{1}{r_k}p(x)$$

#### 增广拉格朗日函数法（乘子法）
惩罚函数法针对惩罚因子 $\rho \rightarrow + \infty$ 或 $\rho \rightarrow 0$ 时，对应的罚函数的海森阵越来越病态，从而导致无约束优化子问题的求解非常困难

**增广拉格朗日函数** $$ L_\sigma(x,\mu) = f(x) + \sum_{i=1}^l\mu_ih_i(x) + \frac{\sigma}{2}\sum_{i=1}^lh_i^2(x)$$
![[Pasted image 20250423131950.png]]
![[Pasted image 20250423132211.png]]
## 多目标规划

基本形式$$ \begin{array}{ll}
\min f_1(x)\\
\min f_2(x)\\
...\\
\min f_p(x)\\
s.t. g_i(x) \le 0,i \in \{1,2,..,m\} \\
\quad h_j(x) = 0, j \in \{1,2,...,l\} \\
\quad x \in X \subseteq R^n\end{array}$$
### 凸多目标规划
若问题（VP）中每个目标函数 $f_i$ 都是凸集上的凸函数，则称(VP) 为凸多目标规划

### 向量序

![[Pasted image 20250423133937.png]]
### 绝对最优解

![[Pasted image 20250423134037.png]]
### 多目标规划的有效解
![[Pasted image 20250423134359.png]]
![[Pasted image 20250423134421.png]]
